""" Configurable brain assembly model for simulations and research.
Author: Daniel Mitropolsky, 2018

This module contains classes to represent different elements of a brain simulation:
	- Area - Represents an individual area of the brain, with the relevant parameters.
	- Connectomes are the connections between neurons. They have weights, which are initialized randomly but
		due to plasticity they can updated every time some neuron fires. These weights are represented by numpy arrays.
		The ones that are not random, because they were influenced by previous projections, are referred to as the 'support'.
	- Winners in a given 'round' are the specific neurons that fired in that round.
		In any specific area, these will be the 'k' neurons with the highest value flown into them.
		These are also the only neurons whose connectome weights get updated.
	- Stimulus - Represents a random stimulus that can be applied to any part of the brain.
		When a stimulus is created it is initialized randomly, but when applied multiple times this will change.
		This is equivalent to k neurons from an unknown part of the brain firing and their (initially, random)
		connectomes decide how this stimulus affects a given area of the brain.
	- Brain - A class representing a simulated brain, with it's different areas, stimulus, and all the connectome weights.
		A brain is initialized as a random graph, and it is maintained in a 'sparse' representation,
		meaning that all neurons that have their original, random connectome weights (0 or 1) are not saved explicitly.
	- Assembly - TODO define and express in code
"""
import heapq
import logging
import math
import random
from collections import defaultdict
from itertools import chain
from typing import List, Mapping, Dict, Union

import numpy as np
from numpy.core._multiarray_umath import ndarray
from scipy.stats import binom
from scipy.stats import truncnorm


class Stimulus:
	""" Represents a random stimulus that can be applied to any part of the brain.
	That is, a specific set of k neurons that fire together that do not reside in
	any of the brain areas. These k neurons can be though of as representing a
	specific input stimulus.
	A stimulus can be connected to any areas and each pair of stimulus neuron and
	an area neuron initially have a synapse with probability p (Brain.p).

	The data for the synaptic weights is found in the downstream areas (the areas
	that this stimulus goes into).

	Attributes:
		k: number of neurons that fire
	"""
	def __init__(self, k: int):
		self.k = k


class BaseArea:
	def __init__(self, name) -> None:
		super().__init__()
		self.name = name
		self.stimulus_beta: Dict[str, float] = {}
		self.area_beta: Dict[str, float] = {}
		self.support_size: int = 0
		self.winners: List[int] = []
		self._new_support_size: int = 0
		self._new_winners: List[int] = []
		self.num_first_winners: int = -1

	def update_winners(self) -> None:
		""" This function updates the list of winners for this area after a projection step.

			TODO: redesign this so that the list of new winners is not saved in area.
		"""
		self.winners = self._new_winners
		self.support_size = self._new_support_size


class Area(BaseArea):
	"""Represents an individual area of the brain.

	The list of neurons that are firing is given by 'winners'. It is updated through application of 'Brain.project',
	where the set of '_new_winners' is calculated and only updated once all brain areas settle on their new winners.
	The winners are the 'k' neurons with the highest value going in each round.

	Initially, most computation are represented implicitly. Winners are represented explicitly, and the changes in
	their incoming synapses are maintained in 'Brain.connectomes' and 'Brain.stimuli_connectomes'. The explicit neurons
	are represented by indices starting with 0 up to 'support_size'-1.

	Since it is initialized randomly, all the programmer needs to provide for initialization is the number 'n' of neurons,
	number 'k' of winners in any given round (meaning the k neurons with heights values will fire),
	and the parameter 'beta' of plasticity controlling connectome weight updates.

	TODO: remove '_new_winners'.
	TODO: remove 'name'. We prefer to use variable names to refer to areas.

	Attributes:
		n: number of neurons in this brain area
		k: number of winners in each round
		beta: plasticity parameter for self-connections
		stimulus_beta: plasticity parameters for connections from each incoming stimulus
		area_beta: plasticity parameters for connections from each incoming area
		support_size: The number of neurons that are represented explicitly (= total number of previous winners)
		winners: List of current winners. That is, 'k' top neurons from previous round.
		_new_support_size: the size of the support for the new update. Should be 'support_size' + 'num_first_winners'.
		_new_winners: During the projection process, a new set of winners is formed. The winners are only
			updated when the projection ends, so that the newly computed winners won't affect computation
		num_first_winners: should be equal to 'len(_new_winners)'
	"""
	def __init__(self, name: str, n: int, k: int, beta: float = 0.05):
		super().__init__(name)
		self.n = n
		self.k = k
		self.beta = beta


class OutputArea(BaseArea):
	n = 1000
	k = 30
	beta = 0.05

	def __init__(self, name: str):
		super().__init__(name)


class Brain:
	"""Represents a simulated brain, with it's different areas, stimuli, and all the synapse weights.

	The brain updates by selecting a subgraph of stimuli and areas, and activating only those connections.


	Attributes:
		areas: A mapping from area names to Area objects representing them.
		stimuli: A mapping from stimulus names to Stimulus objects representing them.
		stimuli_connectomes: Maps each pair of (stimulus,area) to the ndarray representing the synaptic weights among
			stimulus neurons and neurons in the support of area.
		connectomes: Maps each pair of areas to the ndarray representing the synaptic weights among neurons in
			the support.
		p: Probability of connectome (edge) existing between two neurons (vertices)
	"""

	def __init__(self, p: float):
		self.areas: Dict[str, Area] = {}
		self.output_areas: Dict[str, OutputArea] = {}
		self.stimuli: Dict[str, Stimulus] = {}
		self.stimuli_connectomes: Dict[str, Dict[str, ndarray]] = {}
		self.connectomes: Dict[str, Dict[str, ndarray]] = {}

		# OutputArea Connectomes:
		self.output_stimuli_connectomes: Dict[str, Dict[str, List]] = \
			defaultdict(lambda: defaultdict(lambda: [0] * OutputArea.n))
		self.output_connectomes: Dict[str, Dict[str, List]] = \
			defaultdict(lambda: defaultdict(lambda: [[0] * OutputArea.n for i in range(OutputArea.n)]))

		self.p: float = p

	def get_stimulus_connectomes(self, stimulus_name, area_name):
		if area_name in self.output_areas:
			return self.output_stimuli_connectomes[stimulus_name][area_name]
		else:
			return self.stimuli_connectomes[stimulus_name][area_name]

	def get_area_connectomes(self, from_area_name, to_area_name):
		if to_area_name in self.output_areas:
			return self.output_connectomes[from_area_name][to_area_name]
		else:
			return self.connectomes[from_area_name][to_area_name]

	def add_stimulus(self, name: str, k: int) -> None:
		""" Initialize a random stimulus with 'k' neurons firing.
		This stimulus can later be applied to different areas of the brain,
		also updating its outgoing connectomes in the process.

		Connectomes to all areas is initialized as an empty numpy array.
		For every target area, which are all existing areas, set the plasticity coefficient, beta, to equal that area's beta.

		:param name: Name used to refer to stimulus
		:param k: Number of neurons in the stimulus
		"""
		self.stimuli[name]: Stimulus = Stimulus(k)
		new_connectomes: Dict[str, ndarray] = {}
		for key in self.areas:
			new_connectomes[key] = np.empty((0, 0))
			self.areas[key].stimulus_beta[name] = self.areas[key].beta
		self.stimuli_connectomes[name] = new_connectomes

		for key in self.output_areas:
			self.output_areas[key].stimulus_beta[name] = self.output_areas[key].beta
			# TODO: maybe initialize all stimulus connectomes here

	def add_output_area(self, name: str) -> None:
		assert name not in self.areas, "Can't create an output area in this name, an area with this name already exists!"
		self.output_areas[name] = OutputArea(name)

		for stim_name in self.stimuli_connectomes:
			self.output_areas[name].stimulus_beta[stim_name] = self.output_areas[name].beta

		for key in self.areas:
			self.output_areas[name].area_beta[key] = self.output_areas[name].beta

	def add_area(self, name: str, n: int, k: int, beta: float) -> None:
		"""Add an area to this brain, randomly connected to all other areas and stimulus.

		Initialize each synapse weight to have a value of 0 or 1 with probability 'p'.
		Initialize incoming and outgoing connectomes as empty arrays.
		Initialize incoming betas as 'beta'.
		Initialize outgoing betas as the target area.beta

		:param name: Name of area
		:param n: Number of neurons in the new area
		:param k: Number of winners in the new area
		:param beta: plasticity parameter of connectomes coming INTO this area.
				The plasticity parameter of connectomes FROM this area INTO other areas are decided by
				the betas of those other areas.
		"""
		assert name not in self.output_areas, "Can't create an area in this name, an output area with this name already exists!"

		self.areas[name] = Area(name, n, k, beta)

		for stim_name, stim_connectomes in self.stimuli_connectomes.items():
			stim_connectomes[name] = np.empty(0)  # TODO: Should this be np.empty((0,0))?
			# TODO: Answer: No, It's a matrix describing a connectome from the stimulus (single) to the area
			#  neurons (multiple), thus only one dimension is needed. If the stimulus's k neurons will become
			# separate in the future, It will make sense to turn this into a (k * n) matrix.

			self.areas[name].stimulus_beta[stim_name] = beta

		new_connectomes: Dict[str, ndarray] = {}
		for key in self.areas:
			new_connectomes[key] = np.empty((0, 0))
			if key != name:
				self.connectomes[key][name] = np.empty((0, 0))
			self.areas[key].area_beta[name] = self.areas[key].beta
			self.areas[name].area_beta[key] = beta
		self.connectomes[name] = new_connectomes

		# Each output_area[area_beta] gets the beta of the output_area (not the area,
		# since the betas direction is defined to be the 'to beta').
		for key in self.output_areas:
			self.output_areas[key].area_beta[name] = self.output_areas[key].beta

	def project(self, stim_to_area: Mapping[str, List[str]],
					area_to_area: Mapping[str, List[str]]) -> None:
		""" Project is the basic operation where some stimuli and some areas are activated,
		with only specified connections between them active.

		:param stim_to_area: Dictionary that matches to each stimuli applied a list of areas to project into.
			Example: {"stim1":["A"], "stim2":["C","A"]}
		:param area_to_area: Dictionary that matches for each area a list of areas to project into.
			Note that an area can also be projected into itself.
			Example: {"A":["A","B"],"C":["C","A"]}
		"""
		stim_in: defaultdict[str, List[str]] = defaultdict(lambda: [])
		area_in: defaultdict[str, List[str]] = defaultdict(lambda: [])

		# Validate stim_area, area_area well defined
		# Set stim_in to be the Dictionary that matches for every area the list of input stimuli.
		# Set areas_in to be the Dictionary that matches for every area the list of input areas.
		for stim, areas in stim_to_area.items():
			if stim not in self.stimuli:
				raise IndexError(stim + " not in brain.stimuli")
			for area in areas:
				if area not in chain(self.areas, self.output_areas):
					raise IndexError(area + " not in brain.areas")
				stim_in[area].append(stim)
		for from_area, to_areas in area_to_area.items():
			if from_area not in self.areas:
				raise IndexError(from_area + " not in brain.areas")
			for to_area in to_areas:
				if to_area not in chain(self.areas, self.output_areas):
					raise IndexError(to_area + " not in brain.areas")
				area_in[to_area].append(from_area)

		# to_update is the set of all areas that receive input
		to_update = {}
		for area_name in set().union(list(stim_in.keys()), list(area_in.keys())):
			if area_name in self.output_areas:
				to_update[area_name] = self.output_areas[area_name]
			else:
				to_update[area_name] = self.areas[area_name]

		for area, area_obj in to_update.items():
			num_first_winners = self.project_into(area_obj, stim_in[area], area_in[area])
			area_obj.num_first_winners = num_first_winners

		# once done everything, for each area in to_update: area.update_winners()
		for area, area_obj in to_update:
			area_obj.update_winners()

	def project_into(self, area: Union[Area, OutputArea], from_stimuli: List[str], from_areas: List[str]) -> int:
		"""Project multiple stimuli and area assemblies into area 'area' at the same time.

		:param area: The area projected into
		:param from_stimuli: The stimuli that we will be applying
		:param from_areas: List of separate areas whose assemblies we will project into this area
		:return: Returns the number of area neurons that were winners for the first time during this projection
		"""
		# projecting everything in from stim_in[area] and area_in[area]
		# calculate: inputs to self.connectomes[area] (previous winners)
		# calculate: potential new winners, Binomial(sum of in sizes, k-top)
		# k top of previous winners and potential new winners
		# if new winners > 0, redo connectome and intra_connectomes
		# have to wait to replace new_winners
		# TODO Add more documentation to this function which does most of the work
		# TODO Handle case of projecting from an area without previous winners.
		# TODO: there is a bug when adding a new stimulus later on.
		# TODO: Stimulus is updating to somehow represent >100 neurons.
		logging.info(("Projecting " + ",".join(from_stimuli) + " and " + ",".join(from_areas) + " into " + area.name))

		name: str = area.name
		prev_winner_inputs: List[float] = [0.] * area.support_size
		for stim in from_stimuli:
			stim_inputs = self.get_stimulus_connectomes(stim, name)
			for i in range(area.support_size):
				prev_winner_inputs[i] += stim_inputs[i]
		for from_area in from_areas:
			connectome = self.get_area_connectomes(from_area, name)
			for w in self.areas[from_area].winners:
				for i in range(area.support_size):
					prev_winner_inputs[i] += connectome[w][i]

		logging.debug("prev_winner_inputs: %s" % prev_winner_inputs)

		# simulate area.k potential new winners
		total_k: int = 0
		input_sizes: List[int] = []  	# list of the number of winners in each upstream stimulus/area,
										# indexed in the same way as from_areas. TODO: does it makes sense?
		for stim in from_stimuli:
			total_k += self.stimuli[stim].k
			input_sizes.append(self.stimuli[stim].k)
		for from_area in from_areas:
			# if self.areas[from_area].support_size < self.areas[from_area].k:
			#	raise ValueError("Area " + from_area + "does not have enough support.")
			effective_k = len(self.areas[from_area].winners)
			total_k += effective_k
			input_sizes.append(effective_k)

		logging.debug("total_k = " + str(total_k) + " and input_sizes = " + str(input_sizes))

		effective_n = area.n - area.support_size
		# Threshold for inputs that are above (n-k)/n percentile. alpha is the smallest number such that:
		# 							Pr(Bin(total_k,self.p) <= alpha) >= (effective_n-area.k)/effective_n
		alpha = binom.ppf((float(effective_n-area.k)/effective_n), total_k, self.p)
		logging.debug(("Alpha = " + str(alpha)))
		# use normal approximation, between alpha and total_k, round to integer
		# create k potential_new_winners
		std = math.sqrt(total_k * self.p * (1.0-self.p))
		mu = total_k * self.p
		a = float(alpha - mu) / std
		b = float(total_k - mu) / std  # note that b>=a and corresponds to the maximum value of Bin(total_k,self.p)
		potential_new_winners = truncnorm.rvs(a, b, scale=std, loc=mu, size=area.k)
		for i in range(area.k):
			potential_new_winners[i] = round(potential_new_winners[i])
		potential_new_winners = potential_new_winners.tolist()

		logging.debug("potential_new_winners: %s" % potential_new_winners)

		# take max among prev_winner_inputs, potential_new_winners
		# get num_first_winners (think something small)
		# can generate area.new_winners, note the new indices
		both = prev_winner_inputs + potential_new_winners
		new_winner_indices = heapq.nlargest(area.k, list(range(len(both))), both.__getitem__)
		num_first_winners = 0
		first_winner_inputs = []
		for i in range(area.k):
			if new_winner_indices[i] >= area.support_size:  # index in potential_new_winners - a new assembly neuron
				first_winner_inputs.append(potential_new_winners[new_winner_indices[i] - area.support_size])
				new_winner_indices[i] = area.support_size + num_first_winners
				num_first_winners += 1
		area._new_winners = new_winner_indices # Note that from here on 'new_winner_indices' is not in use.
		area._new_support_size = area.support_size + num_first_winners

		logging.debug("new_winners: %s" % area._new_winners)

		# for i in num_first_winners
		# generate where input came from
		# 	1) can sample input from array of size total_k, use ranges
		# 	2) can use stars/stripes method: if m total inputs, sample (m-1) out of total_k
		first_winner_to_inputs: Dict[int, ndarray] = {}
		for i in range(num_first_winners):
			input_indices = random.sample(range(0, total_k), int(first_winner_inputs[i]))
			inputs: ndarray = np.zeros(len(input_sizes))
			total_so_far = 0
			for j in range(len(input_sizes)):
				# inputs[j] is the randomly generated number of connections from the j'th input to area i.
				inputs[j] = sum([((total_so_far + input_sizes[j]) > w >= total_so_far) for w in input_indices])
				total_so_far += input_sizes[j]
			first_winner_to_inputs[i] = inputs
			logging.debug("for first_winner #%d with input %s split as so: %s" % (i, first_winner_inputs[i], inputs))

		m = 0
		# connectome for each stim->area
			# add num_first_winners cells, sampled input * (1+beta)
			# for i in repeat_winners, stimulus_inputs[i] *= (1+beta)
		for stim in from_stimuli:
			if num_first_winners > 0:
				if name in self.areas:
					self.stimuli_connectomes[stim][name] = np.resize(
						self.stimuli_connectomes[stim][name],
						area.support_size + num_first_winners
					)
			for i in range(num_first_winners):
				self.get_stimulus_connectomes(stim, name)[area.support_size + i] = first_winner_to_inputs[i][m]
			stim_to_area_beta = area.stimulus_beta[stim]
			for i in area._new_winners:
				self.get_stimulus_connectomes(stim, name)[i] *= (1+stim_to_area_beta)
			logging.debug("stimulus %s now looks like: %s" % (stim, self.get_stimulus_connectomes(stim, name)))
			m += 1

		# connectome for each in_area->area
			# add num_first_winners columns
			# for each i in num_first_winners, fill in (1+beta) for chosen neurons
			# for each i in repeat_winners, for j in in_area.winners, connectome[j][i] *= (1+beta)
		for from_area in from_areas:
			from_area_w = self.areas[from_area].support_size
			from_area_winners = self.areas[from_area].winners
			if name in self.areas:
				self.connectomes[from_area][name] = np.pad(
					self.connectomes[from_area][name], ((0, 0), (0, num_first_winners)), 'constant', constant_values=0
				)
			for i in range(num_first_winners):
				total_in = first_winner_to_inputs[i][m]
				sample_indices = random.sample(from_area_winners, int(total_in))
				for j in range(from_area_w):
					if j in sample_indices:
						self.get_area_connectomes(from_area, name)[j][area.support_size + i] = 1
					if j not in from_area_winners:
						self.get_area_connectomes(from_area, name)[j][area.support_size + i] = np.random.binomial(1, self.p)
			area_to_area_beta = area.area_beta[from_area]
			for i in area._new_winners:
				for j in from_area_winners:
					self.get_area_connectomes(from_area, name)[j][i] *= (1.0 +area_to_area_beta)
			logging.debug("Connectome of %s to %s is now %s" % (from_area, name, self.get_area_connectomes(from_area, name)))
			m += 1

		# expand connectomes from other areas that did not fire into area
		# also expand connectome for area->other_area
		for other_area in self.areas:
			if other_area not in from_areas:
				if name in self.areas:
					self.connectomes[other_area][name] = np.pad(self.connectomes[other_area][name],
						((0,0),(0,num_first_winners)), 'constant', constant_values=0)
				for j in range(self.areas[other_area].support_size):
					for i in range(area.support_size, area._new_support_size):
						self.get_area_connectomes(other_area, name)[j][i] = np.random.binomial(1, self.p)
			# add num_first_winners rows, all bernoulli with probability p
			# TODO: Should all this be indented?
			if name in self.areas:
				self.connectomes[name][other_area] = np.pad(self.connectomes[name][other_area],
					((0, num_first_winners),(0, 0)), 'constant', constant_values=0)
				columns = len(self.connectomes[name][other_area][0])
				for i in range(area.support_size, area._new_support_size):
					for j in range(columns):
						self.connectomes[name][other_area][i][j] = np.random.binomial(1, self.p)
			logging.debug("Connectome of %s to %s is now: %s" % (name, other_area, self.connectomes[name][other_area]))

		return num_first_winners












